[train] host=lfs-dev date=2026-02-11T01:09:52+08:00
[train] cuda=NVIDIA GeForce RTX 5090, 32607 MiB;
[train] args: --run-name ts_bs32_lr1e3_5k --out-dir artifacts/experiments/lm --train-data artifacts/tokenized/tinystories_train.bin --valid-data artifacts/tokenized/tinystories_valid.bin --vocab-size 10000 --context-length 256 --d-model 512 --num-layers 4 --num-heads 16 --d-ff 1344 --batch-size 32 --max-iters 5000 --eval-interval 250 --eval-batches 30 --log-interval 50 --save-interval 500 --learning-rate 1e-3 --min-learning-rate 1e-4 --warmup-iters 200 --device cuda --dtype bfloat16 --tokenizer-vocab artifacts/bpe/tinystories/vocab.jsonl --tokenizer-merges artifacts/bpe/tinystories/merges.jsonl --generate-prompt Once upon a time --max-new-tokens 256 --top-k 50
[iter 000000] loss=9.2641 lr=0.00e+00 tokens_seen=8192 elapsed=0.5s
[eval 000000] train_loss=9.2692 val_loss=9.2679 best_val=inf
[iter 000050] loss=5.6806 lr=2.50e-04 tokens_seen=417792 elapsed=2.1s
[iter 000100] loss=3.8755 lr=5.00e-04 tokens_seen=827392 elapsed=3.2s
[iter 000150] loss=3.4029 lr=7.50e-04 tokens_seen=1236992 elapsed=4.3s
[iter 000200] loss=3.3161 lr=1.00e-03 tokens_seen=1646592 elapsed=5.4s
[iter 000250] loss=2.9064 lr=1.00e-03 tokens_seen=2056192 elapsed=6.6s
[eval 000250] train_loss=2.9887 val_loss=2.9237 best_val=9.2679
[iter 000300] loss=2.7695 lr=9.99e-04 tokens_seen=2465792 elapsed=8.3s
[iter 000350] loss=2.6011 lr=9.98e-04 tokens_seen=2875392 elapsed=9.4s
[iter 000400] loss=2.6245 lr=9.96e-04 tokens_seen=3284992 elapsed=10.5s
[iter 000450] loss=2.4753 lr=9.94e-04 tokens_seen=3694592 elapsed=11.6s
[iter 000500] loss=2.4576 lr=9.91e-04 tokens_seen=4104192 elapsed=12.8s
[eval 000500] train_loss=2.5156 val_loss=2.4881 best_val=2.9237
[iter 000550] loss=2.4517 lr=9.88e-04 tokens_seen=4513792 elapsed=14.7s
[iter 000600] loss=2.4926 lr=9.85e-04 tokens_seen=4923392 elapsed=15.8s
[iter 000650] loss=2.3532 lr=9.81e-04 tokens_seen=5332992 elapsed=16.9s
[iter 000700] loss=2.3601 lr=9.76e-04 tokens_seen=5742592 elapsed=18.0s
[iter 000750] loss=2.3321 lr=9.71e-04 tokens_seen=6152192 elapsed=19.2s
[eval 000750] train_loss=2.3343 val_loss=2.3253 best_val=2.4881
[iter 000800] loss=2.2541 lr=9.66e-04 tokens_seen=6561792 elapsed=20.9s
[iter 000850] loss=2.2457 lr=9.60e-04 tokens_seen=6971392 elapsed=22.0s
[iter 000900] loss=2.0800 lr=9.54e-04 tokens_seen=7380992 elapsed=23.1s
[iter 000950] loss=2.3038 lr=9.47e-04 tokens_seen=7790592 elapsed=24.2s
[iter 001000] loss=2.1795 lr=9.40e-04 tokens_seen=8200192 elapsed=25.3s
[eval 001000] train_loss=2.2105 val_loss=2.2193 best_val=2.3253
[iter 001050] loss=2.1035 lr=9.32e-04 tokens_seen=8609792 elapsed=27.3s
[iter 001100] loss=2.2179 lr=9.24e-04 tokens_seen=9019392 elapsed=28.5s
[iter 001150] loss=2.1869 lr=9.16e-04 tokens_seen=9428992 elapsed=29.6s
[iter 001200] loss=2.2465 lr=9.07e-04 tokens_seen=9838592 elapsed=30.7s
[iter 001250] loss=2.0578 lr=8.98e-04 tokens_seen=10248192 elapsed=31.8s
[eval 001250] train_loss=2.1273 val_loss=2.1308 best_val=2.2193
[iter 001300] loss=2.2614 lr=8.88e-04 tokens_seen=10657792 elapsed=33.5s
[iter 001350] loss=2.0255 lr=8.78e-04 tokens_seen=11067392 elapsed=34.6s
[iter 001400] loss=1.9729 lr=8.68e-04 tokens_seen=11476992 elapsed=35.7s
[iter 001450] loss=2.0950 lr=8.58e-04 tokens_seen=11886592 elapsed=36.9s
[iter 001500] loss=2.0171 lr=8.47e-04 tokens_seen=12296192 elapsed=38.0s
[eval 001500] train_loss=2.0360 val_loss=2.0521 best_val=2.1308
[iter 001550] loss=2.1514 lr=8.35e-04 tokens_seen=12705792 elapsed=40.0s
[iter 001600] loss=2.1256 lr=8.24e-04 tokens_seen=13115392 elapsed=41.1s
[iter 001650] loss=2.0396 lr=8.12e-04 tokens_seen=13524992 elapsed=42.2s
[iter 001700] loss=2.0807 lr=8.00e-04 tokens_seen=13934592 elapsed=43.3s
[iter 001750] loss=2.0117 lr=7.88e-04 tokens_seen=14344192 elapsed=44.4s
[eval 001750] train_loss=2.0127 val_loss=2.0031 best_val=2.0521
[iter 001800] loss=2.0317 lr=7.75e-04 tokens_seen=14753792 elapsed=46.1s
[iter 001850] loss=1.9617 lr=7.62e-04 tokens_seen=15163392 elapsed=47.3s
[iter 001900] loss=2.0655 lr=7.49e-04 tokens_seen=15572992 elapsed=48.4s
[iter 001950] loss=1.9081 lr=7.36e-04 tokens_seen=15982592 elapsed=49.5s
[iter 002000] loss=1.7868 lr=7.22e-04 tokens_seen=16392192 elapsed=50.6s
[eval 002000] train_loss=1.9495 val_loss=1.9639 best_val=2.0031
[iter 002050] loss=1.9885 lr=7.09e-04 tokens_seen=16801792 elapsed=52.6s
[iter 002100] loss=1.8988 lr=6.95e-04 tokens_seen=17211392 elapsed=53.7s
[iter 002150] loss=2.0126 lr=6.81e-04 tokens_seen=17620992 elapsed=54.8s
[iter 002200] loss=1.8975 lr=6.66e-04 tokens_seen=18030592 elapsed=55.9s
[iter 002250] loss=1.8954 lr=6.52e-04 tokens_seen=18440192 elapsed=57.0s
[eval 002250] train_loss=1.9491 val_loss=1.8970 best_val=1.9639
[iter 002300] loss=1.9318 lr=6.38e-04 tokens_seen=18849792 elapsed=58.8s
[iter 002350] loss=1.9513 lr=6.23e-04 tokens_seen=19259392 elapsed=59.9s
[iter 002400] loss=1.9259 lr=6.09e-04 tokens_seen=19668992 elapsed=61.0s
[iter 002450] loss=1.8988 lr=5.94e-04 tokens_seen=20078592 elapsed=62.1s
[iter 002500] loss=1.8556 lr=5.79e-04 tokens_seen=20488192 elapsed=63.2s
[eval 002500] train_loss=1.8833 val_loss=1.8754 best_val=1.8970
[iter 002550] loss=1.9653 lr=5.65e-04 tokens_seen=20897792 elapsed=65.2s
[iter 002600] loss=1.8132 lr=5.50e-04 tokens_seen=21307392 elapsed=66.4s
[iter 002650] loss=1.8014 lr=5.35e-04 tokens_seen=21716992 elapsed=67.5s
[iter 002700] loss=1.8270 lr=5.21e-04 tokens_seen=22126592 elapsed=68.6s
[iter 002750] loss=1.8212 lr=5.06e-04 tokens_seen=22536192 elapsed=69.7s
[eval 002750] train_loss=1.8503 val_loss=1.8561 best_val=1.8754
[iter 002800] loss=1.8100 lr=4.91e-04 tokens_seen=22945792 elapsed=71.4s
[iter 002850] loss=1.8781 lr=4.77e-04 tokens_seen=23355392 elapsed=72.5s
[iter 002900] loss=1.8479 lr=4.62e-04 tokens_seen=23764992 elapsed=73.6s
[iter 002950] loss=1.8044 lr=4.48e-04 tokens_seen=24174592 elapsed=74.8s
[iter 003000] loss=1.7912 lr=4.34e-04 tokens_seen=24584192 elapsed=75.9s
[eval 003000] train_loss=1.8668 val_loss=1.8360 best_val=1.8561
[iter 003050] loss=1.9073 lr=4.19e-04 tokens_seen=24993792 elapsed=77.9s
[iter 003100] loss=1.8298 lr=4.05e-04 tokens_seen=25403392 elapsed=79.0s
[iter 003150] loss=1.9566 lr=3.91e-04 tokens_seen=25812992 elapsed=80.1s
[iter 003200] loss=1.7594 lr=3.78e-04 tokens_seen=26222592 elapsed=81.2s
[iter 003250] loss=1.8574 lr=3.64e-04 tokens_seen=26632192 elapsed=82.3s
[eval 003250] train_loss=1.8037 val_loss=1.7947 best_val=1.8360
[iter 003300] loss=1.7746 lr=3.51e-04 tokens_seen=27041792 elapsed=84.0s
[iter 003350] loss=1.8193 lr=3.38e-04 tokens_seen=27451392 elapsed=85.1s
[iter 003400] loss=1.6557 lr=3.25e-04 tokens_seen=27860992 elapsed=86.3s
[iter 003450] loss=1.7601 lr=3.12e-04 tokens_seen=28270592 elapsed=87.4s
[iter 003500] loss=1.6465 lr=3.00e-04 tokens_seen=28680192 elapsed=88.5s
[eval 003500] train_loss=1.8049 val_loss=1.7863 best_val=1.7947
[iter 003550] loss=1.7576 lr=2.88e-04 tokens_seen=29089792 elapsed=90.5s
[iter 003600] loss=1.6305 lr=2.76e-04 tokens_seen=29499392 elapsed=91.6s
[iter 003650] loss=1.8701 lr=2.65e-04 tokens_seen=29908992 elapsed=92.7s
[iter 003700] loss=1.8220 lr=2.53e-04 tokens_seen=30318592 elapsed=93.8s
[iter 003750] loss=1.6790 lr=2.42e-04 tokens_seen=30728192 elapsed=95.0s
[eval 003750] train_loss=1.7083 val_loss=1.7447 best_val=1.7863
[iter 003800] loss=1.6465 lr=2.32e-04 tokens_seen=31137792 elapsed=96.7s
[iter 003850] loss=1.7602 lr=2.22e-04 tokens_seen=31547392 elapsed=97.8s
[iter 003900] loss=1.8298 lr=2.12e-04 tokens_seen=31956992 elapsed=98.9s
[iter 003950] loss=1.7440 lr=2.02e-04 tokens_seen=32366592 elapsed=100.1s
[iter 004000] loss=1.7815 lr=1.93e-04 tokens_seen=32776192 elapsed=101.2s
[eval 004000] train_loss=1.7142 val_loss=1.7380 best_val=1.7447
[iter 004050] loss=1.7329 lr=1.84e-04 tokens_seen=33185792 elapsed=103.2s
[iter 004100] loss=1.8355 lr=1.76e-04 tokens_seen=33595392 elapsed=104.3s
[iter 004150] loss=1.7011 lr=1.68e-04 tokens_seen=34004992 elapsed=105.4s
[iter 004200] loss=1.7082 lr=1.60e-04 tokens_seen=34414592 elapsed=106.5s
[iter 004250] loss=1.6612 lr=1.53e-04 tokens_seen=34824192 elapsed=107.6s
[eval 004250] train_loss=1.7505 val_loss=1.7118 best_val=1.7380
[iter 004300] loss=1.5183 lr=1.46e-04 tokens_seen=35233792 elapsed=109.3s
[iter 004350] loss=1.6954 lr=1.40e-04 tokens_seen=35643392 elapsed=110.5s
[iter 004400] loss=1.7515 lr=1.34e-04 tokens_seen=36052992 elapsed=111.6s
[iter 004450] loss=1.7100 lr=1.29e-04 tokens_seen=36462592 elapsed=112.7s
[iter 004500] loss=1.7858 lr=1.24e-04 tokens_seen=36872192 elapsed=113.8s
[eval 004500] train_loss=1.7275 val_loss=1.7050 best_val=1.7118
[iter 004550] loss=1.7230 lr=1.19e-04 tokens_seen=37281792 elapsed=115.8s
[iter 004600] loss=1.7244 lr=1.15e-04 tokens_seen=37691392 elapsed=116.9s
[iter 004650] loss=1.6817 lr=1.12e-04 tokens_seen=38100992 elapsed=118.0s
[iter 004700] loss=1.6750 lr=1.09e-04 tokens_seen=38510592 elapsed=119.2s
[iter 004750] loss=1.7620 lr=1.06e-04 tokens_seen=38920192 elapsed=120.3s
[eval 004750] train_loss=1.7308 val_loss=1.7070 best_val=1.7050
[iter 004800] loss=1.7012 lr=1.04e-04 tokens_seen=39329792 elapsed=121.7s
[iter 004850] loss=1.7540 lr=1.02e-04 tokens_seen=39739392 elapsed=122.8s
[iter 004900] loss=1.6945 lr=1.01e-04 tokens_seen=40148992 elapsed=123.9s
[iter 004950] loss=1.6536 lr=1.00e-04 tokens_seen=40558592 elapsed=125.0s
[eval 004999] train_loss=1.7192 val_loss=1.6665 best_val=1.7050
Training summary: {"run_name": "ts_bs32_lr1e3_5k", "best_val_loss": 1.6664995431900025, "max_iters": 5000, "tokens_seen": 40960000, "elapsed_sec": 126.9878063229844}
Saved generated text to artifacts/experiments/lm/ts_bs32_lr1e3_5k/generated.txt
